{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Read the Feather file\n",
    "df = pd.read_feather('CRSP_daily_data_for_project(Technical_Analysis).feather')\n",
    "# df = df[(df['PERMNO']==10000) |( df['PERMNO']==10001)|(df['PERMNO']==10002)| (df['PERMNO']==93434)|(df['PERMNO']==93435)|(df['PERMNO']==93436)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['PERMNO']==10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df['date']=pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "# df['date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['date','PERMNO'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nq/svc2nf551n74zpynk96y1b7w0000gn/T/ipykernel_13135/382757337.py:1: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['Ret'] = df.groupby('PERMNO')['Close'].apply(lambda x: x.shift(-1).pct_change()).reset_index(level=0, drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>Ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19071</th>\n",
       "      <td>10006</td>\n",
       "      <td>1969-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.25000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>63.125</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>5641.0</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38825</th>\n",
       "      <td>10014</td>\n",
       "      <td>1969-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.25000</td>\n",
       "      <td>15.37500</td>\n",
       "      <td>15.375</td>\n",
       "      <td>21100.0</td>\n",
       "      <td>4109.0</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164917</th>\n",
       "      <td>10057</td>\n",
       "      <td>1969-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.37500</td>\n",
       "      <td>28.12500</td>\n",
       "      <td>28.250</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293514</th>\n",
       "      <td>10102</td>\n",
       "      <td>1969-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.12500</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>33.500</td>\n",
       "      <td>12300.0</td>\n",
       "      <td>11036.0</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386105</th>\n",
       "      <td>10137</td>\n",
       "      <td>1969-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.62500</td>\n",
       "      <td>24.12500</td>\n",
       "      <td>24.500</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>19292.0</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92907830</th>\n",
       "      <td>93423</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>24.92000</td>\n",
       "      <td>25.25000</td>\n",
       "      <td>24.64440</td>\n",
       "      <td>25.080</td>\n",
       "      <td>1306363.0</td>\n",
       "      <td>83537.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92918058</th>\n",
       "      <td>93426</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>33.79000</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>33.79000</td>\n",
       "      <td>34.070</td>\n",
       "      <td>94057.0</td>\n",
       "      <td>12510.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92926793</th>\n",
       "      <td>93429</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>177.85001</td>\n",
       "      <td>179.09000</td>\n",
       "      <td>177.44000</td>\n",
       "      <td>178.560</td>\n",
       "      <td>521913.0</td>\n",
       "      <td>105556.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92933480</th>\n",
       "      <td>93434</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.71495</td>\n",
       "      <td>0.58500</td>\n",
       "      <td>0.700</td>\n",
       "      <td>169185.0</td>\n",
       "      <td>43039.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92937369</th>\n",
       "      <td>93436</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>255.10001</td>\n",
       "      <td>255.19000</td>\n",
       "      <td>247.42999</td>\n",
       "      <td>248.480</td>\n",
       "      <td>100321201.0</td>\n",
       "      <td>3178921.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69075952 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PERMNO       date       Open       High        Low    Close  \\\n",
       "19071      10006 1969-01-02        NaN   63.25000   63.00000   63.125   \n",
       "38825      10014 1969-01-02        NaN   16.25000   15.37500   15.375   \n",
       "164917     10057 1969-01-02        NaN   28.37500   28.12500   28.250   \n",
       "293514     10102 1969-01-02        NaN   34.12500   33.25000   33.500   \n",
       "386105     10137 1969-01-02        NaN   24.62500   24.12500   24.500   \n",
       "...          ...        ...        ...        ...        ...      ...   \n",
       "92907830   93423 2023-12-29   24.92000   25.25000   24.64440   25.080   \n",
       "92918058   93426 2023-12-29   33.79000   34.50000   33.79000   34.070   \n",
       "92926793   93429 2023-12-29  177.85001  179.09000  177.44000  178.560   \n",
       "92933480   93434 2023-12-29    0.62000    0.71495    0.58500    0.700   \n",
       "92937369   93436 2023-12-29  255.10001  255.19000  247.42999  248.480   \n",
       "\n",
       "               Volume     SHROUT    vwretx    ewretx    sprtrn  Ret  \n",
       "19071          3400.0     5641.0  0.001022  0.005752  0.000674  NaN  \n",
       "38825         21100.0     4109.0  0.001022  0.005752  0.000674  NaN  \n",
       "164917         1300.0     2038.0  0.001022  0.005752  0.000674  NaN  \n",
       "293514        12300.0    11036.0  0.001022  0.005752  0.000674  NaN  \n",
       "386105         2400.0    19292.0  0.001022  0.005752  0.000674  NaN  \n",
       "...               ...        ...       ...       ...       ...  ...  \n",
       "92907830    1306363.0    83537.0 -0.004084 -0.007546 -0.002826  0.0  \n",
       "92918058      94057.0    12510.0 -0.004084 -0.007546 -0.002826  0.0  \n",
       "92926793     521913.0   105556.0 -0.004084 -0.007546 -0.002826  0.0  \n",
       "92933480     169185.0    43039.0 -0.004084 -0.007546 -0.002826  0.0  \n",
       "92937369  100321201.0  3178921.0 -0.004084 -0.007546 -0.002826  0.0  \n",
       "\n",
       "[69075952 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ret'] = df.groupby('PERMNO')['Close'].apply(lambda x: x.shift(-1).pct_change()).reset_index(level=0, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ret'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>sprtrn</th>\n",
       "      <th>Ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>1969-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.75000</td>\n",
       "      <td>63.12500</td>\n",
       "      <td>63.500</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>5641.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014</td>\n",
       "      <td>1969-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.75000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.125</td>\n",
       "      <td>26500.0</td>\n",
       "      <td>4109.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.016529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10057</td>\n",
       "      <td>1969-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.37500</td>\n",
       "      <td>27.87500</td>\n",
       "      <td>28.250</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>2038.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10102</td>\n",
       "      <td>1969-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.87500</td>\n",
       "      <td>33.37500</td>\n",
       "      <td>33.500</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>11036.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-0.026119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10137</td>\n",
       "      <td>1969-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.75000</td>\n",
       "      <td>24.37500</td>\n",
       "      <td>24.750</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>19292.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>-0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68992266</th>\n",
       "      <td>93423</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>24.92000</td>\n",
       "      <td>25.25000</td>\n",
       "      <td>24.64440</td>\n",
       "      <td>25.080</td>\n",
       "      <td>1306363.0</td>\n",
       "      <td>83537.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68992267</th>\n",
       "      <td>93426</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>33.79000</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>33.79000</td>\n",
       "      <td>34.070</td>\n",
       "      <td>94057.0</td>\n",
       "      <td>12510.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68992268</th>\n",
       "      <td>93429</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>177.85001</td>\n",
       "      <td>179.09000</td>\n",
       "      <td>177.44000</td>\n",
       "      <td>178.560</td>\n",
       "      <td>521913.0</td>\n",
       "      <td>105556.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68992269</th>\n",
       "      <td>93434</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>0.71495</td>\n",
       "      <td>0.58500</td>\n",
       "      <td>0.700</td>\n",
       "      <td>169185.0</td>\n",
       "      <td>43039.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68992270</th>\n",
       "      <td>93436</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>255.10001</td>\n",
       "      <td>255.19000</td>\n",
       "      <td>247.42999</td>\n",
       "      <td>248.480</td>\n",
       "      <td>100321201.0</td>\n",
       "      <td>3178921.0</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.002826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68992271 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PERMNO       date       Open       High        Low    Close  \\\n",
       "0          10006 1969-01-03        NaN   63.75000   63.12500   63.500   \n",
       "1          10014 1969-01-03        NaN   15.75000   15.00000   15.125   \n",
       "2          10057 1969-01-03        NaN   28.37500   27.87500   28.250   \n",
       "3          10102 1969-01-03        NaN   33.87500   33.37500   33.500   \n",
       "4          10137 1969-01-03        NaN   24.75000   24.37500   24.750   \n",
       "...          ...        ...        ...        ...        ...      ...   \n",
       "68992266   93423 2023-12-29   24.92000   25.25000   24.64440   25.080   \n",
       "68992267   93426 2023-12-29   33.79000   34.50000   33.79000   34.070   \n",
       "68992268   93429 2023-12-29  177.85001  179.09000  177.44000  178.560   \n",
       "68992269   93434 2023-12-29    0.62000    0.71495    0.58500    0.700   \n",
       "68992270   93436 2023-12-29  255.10001  255.19000  247.42999  248.480   \n",
       "\n",
       "               Volume     SHROUT    vwretx    ewretx    sprtrn       Ret  \n",
       "0              3600.0     5641.0  0.000115  0.001501  0.000577 -0.007874  \n",
       "1             26500.0     4109.0  0.000115  0.001501  0.000577  0.016529  \n",
       "2              2600.0     2038.0  0.000115  0.001501  0.000577  0.000000  \n",
       "3             11300.0    11036.0  0.000115  0.001501  0.000577 -0.026119  \n",
       "4              3900.0    19292.0  0.000115  0.001501  0.000577 -0.015152  \n",
       "...               ...        ...       ...       ...       ...       ...  \n",
       "68992266    1306363.0    83537.0 -0.004084 -0.007546 -0.002826  0.000000  \n",
       "68992267      94057.0    12510.0 -0.004084 -0.007546 -0.002826  0.000000  \n",
       "68992268     521913.0   105556.0 -0.004084 -0.007546 -0.002826  0.000000  \n",
       "68992269     169185.0    43039.0 -0.004084 -0.007546 -0.002826  0.000000  \n",
       "68992270  100321201.0  3178921.0 -0.004084 -0.007546 -0.002826  0.000000  \n",
       "\n",
       "[68992271 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['Ret'].isnull()].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['date'].dt.is_month_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2303257, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Generate CQT data for each stock\n",
    "def create_cqt_df(stock_df, n_bins=20):\n",
    "    stock_returns = stock_df['vwretx'].values\n",
    "\n",
    "    # Data preprocessing: Ensure all values are finite\n",
    "    stock_returns = np.nan_to_num(stock_returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    sr = 1\n",
    "    fmin = 0.01  # Minimum frequency\n",
    "    hop_length = 1\n",
    "    cqt_result = librosa.cqt(stock_returns, n_bins=n_bins, sr=sr, hop_length=hop_length, fmin=fmin)\n",
    "    cqt_result_db = librosa.amplitude_to_db(np.abs(cqt_result), ref=np.mean)\n",
    "\n",
    "    cqt_df = pd.DataFrame(cqt_result_db.T, columns=[f'CQT_{i+1}' for i in range(cqt_result_db.shape[0])])\n",
    "    cqt_df = cqt_df.loc[:len(stock_df)-1, :]  # Ensure the length matches the original data\n",
    "    cqt = pd.concat([stock_df['date'], cqt_df], axis=1)\n",
    "    return cqt\n",
    "\n",
    "# Function: Create rolling windows and retain date indices\n",
    "def create_rolling_windows_with_dates(data, cqt_window_size, date_to_index):\n",
    "    windows = []\n",
    "    date_indices = []\n",
    "    for i in range(len(data) - cqt_window_size + 1):\n",
    "        window = data.iloc[i:i + cqt_window_size, 1:].values  # Exclude the date column, keep only CQT data\n",
    "        windows.append(window)\n",
    "        start_date = data.iloc[i]['date']\n",
    "        if start_date in date_to_index:\n",
    "            date_indices.append(date_to_index[start_date])\n",
    "    return np.array(windows), date_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_processed_data(df, start_date, end_date, window_size=3):\n",
    "    \n",
    "    df_sub = df[(df['date']>=start_date) & (df['date']<end_date)]\n",
    "\n",
    "    # Get the list of all stock codes\n",
    "    stock_codes = set(df_sub['PERMNO'].unique())\n",
    "    # stock_codes = set()\n",
    "\n",
    "    cqt_window_size = window_size\n",
    "    n_bins = 2  # Number of CQT bins\n",
    "\n",
    "    # Get all unique dates\n",
    "    unique_dates = df_sub['date'].unique()\n",
    "\n",
    "    # drop the PERMNO for which data is not available on all unique_dates\n",
    "    for _,r in df_sub.groupby(['date']):\n",
    "        stock_codes.intersection_update(set(r['PERMNO'].to_list()))\n",
    "\n",
    "    stock_codes = list(stock_codes)\n",
    "    \n",
    "    df_sub = df_sub[df_sub['PERMNO'].isin(stock_codes)]\n",
    "    \n",
    "    # Create the 4D array, initialized with NaN\n",
    "    num_dates = len(unique_dates)\n",
    "    max_shape = (len(stock_codes), num_dates - cqt_window_size + 1, cqt_window_size, n_bins)\n",
    "    final_4d_array = np.full(max_shape, np.nan)\n",
    "\n",
    "    # Create the date-to-index mapping\n",
    "    date_to_index = {date: idx for idx, date in enumerate(unique_dates)}\n",
    "\n",
    "    # Create the stock code-to-index mapping\n",
    "    stock_code_to_index = {stock_code: idx for idx, stock_code in enumerate(stock_codes)}\n",
    "\n",
    "    # Iterate over each stock and fill the 4D array\n",
    "    for stock_code in stock_codes:\n",
    "        stock_idx = stock_code_to_index[stock_code]\n",
    "        stock_data = df_sub[df_sub['PERMNO'] == stock_code].reset_index(drop=True)\n",
    "        \n",
    "        # Generate CQT data\n",
    "        cqt_data = create_cqt_df(stock_data, n_bins)\n",
    "\n",
    "        # Create rolling windows and retain date indices\n",
    "        rolling_windows_3d, date_indices = create_rolling_windows_with_dates(cqt_data, cqt_window_size, date_to_index)\n",
    "        \n",
    "        # Fill the 4D array\n",
    "        for window_idx, (window_data, date_idx) in enumerate(zip(rolling_windows_3d, date_indices)):\n",
    "            if window_data.shape == (cqt_window_size, n_bins):\n",
    "                final_4d_array[stock_idx, date_idx, :, :] = window_data\n",
    "\n",
    "    # df_sub = df_sub.sort_values(by=['PERMNO', 'date'])\n",
    "    # df_sub['Ret'] = df_sub.groupby('PERMNO')['Close'].apply(lambda x: x.shift(-1).pct_change()).reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    return final_4d_array, df_sub, stock_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1969-01-31 00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2007-01-31 00:00:00', '2007-02-28 00:00:00', '2007-04-30 00:00:00',\n",
       " '2007-05-31 00:00:00', '2007-07-31 00:00:00', '2007-08-31 00:00:00',\n",
       " '2007-10-31 00:00:00', '2007-11-30 00:00:00', '2007-12-31 00:00:00']\n",
       "Length: 9, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['date'].dt.year==2007]['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df[df['date'].dt.year==2000]['date'].min()\n",
    "end_date = df[df['date'].dt.year==2023]['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime.strptime(\"2000-01-01\", \"%Y-%m-%d\")\n",
    "# end_date = datetime.strptime(\"2001-01-01\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# final_4d_array, df_sub, stock_codes = get_pre_processed_data(df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock=0\n",
    "# stock_data = final_4d_array[stock]\n",
    "# ret = df_sub[df_sub.PERMNO == stock_codes[stock]]['Ret'].values[-stock_data.shape[0]:].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(final_4d_array.shape[1], 1)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# stock_data = scaler.fit_transform(stock_data.reshape(stock_data.shape[0], stock_data.shape[1] * stock_data.shape[2]))\n",
    "\n",
    "# # Split the data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(stock_data, ret, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LSTM model to the CQT data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lstm_model(final_4d_array, df_sub, stock_codes, date):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5, input_shape=(final_4d_array.shape[1], 1)))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # make an array to store all X_test\n",
    "    X_test_array = None\n",
    "    y_test_array = None\n",
    "    X_train_array = None\n",
    "    y_train_array = None\n",
    "\n",
    "    # returns = np.array([])\n",
    "\n",
    "    for stock in range(final_4d_array.shape[0]):\n",
    "        stock_data = final_4d_array[stock]\n",
    "        ret = df_sub[df_sub.PERMNO == stock_codes[stock]]['Ret'].values[-stock_data.shape[0]:].reshape(-1, 1)\n",
    "        # returns = np.append(returns, ret)\n",
    "\n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler()\n",
    "        stock_data = scaler.fit_transform(stock_data.reshape(stock_data.shape[0], stock_data.shape[1] * stock_data.shape[2]))\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        # print(stock_data.shape, ret.shape)\n",
    "        # X_train = stock_data[:10]\n",
    "        # y_train = stock_data[:10]\n",
    "        # X_test = ret[10:]\n",
    "        # y_test = ret[10:]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(stock_data, ret, test_size=0.5, shuffle=False)\n",
    "\n",
    "        if X_test_array is None:\n",
    "            X_test_array = np.zeros((final_4d_array.shape[0], X_test.shape[0], X_test.shape[1]))\n",
    "        if X_train_array is None:\n",
    "            X_train_array = np.zeros((final_4d_array.shape[0], X_train.shape[0], X_train.shape[1]))\n",
    "        \n",
    "        if y_test_array is None:\n",
    "            y_test_array = np.zeros((final_4d_array.shape[0], y_test.shape[0], y_test.shape[1]))\n",
    "        if y_train_array is None:\n",
    "            y_train_array = np.zeros((final_4d_array.shape[0], y_train.shape[0], y_train.shape[1]))\n",
    "            \n",
    "        X_test_array[stock] = X_test\n",
    "        X_train_array[stock] = X_train\n",
    "        y_test_array[stock] = y_test\n",
    "        y_train_array[stock] = y_train\n",
    "\n",
    "    X_train_array = X_train_array.reshape(X_train_array.shape[0] * X_train_array.shape[1], X_train_array.shape[2])\n",
    "    y_train_array = y_train_array.reshape(y_train_array.shape[0] * y_train_array.shape[1], y_train_array.shape[2])\n",
    "    # Train the model\n",
    "    train_loss = model.fit(X_train_array, y_train_array, epochs=2, batch_size=32)\n",
    "    \n",
    "    print(\"Train loss:\", train_loss.history['loss'][-1])\n",
    "\n",
    "\n",
    "    all_predictions = {\n",
    "        date.year: {}\n",
    "    }\n",
    "    \n",
    "    for stock in range(final_4d_array.shape[0]):\n",
    "        stock_data = final_4d_array[stock]\n",
    "        stock_data = stock_data.reshape(stock_data.shape[0], stock_data.shape[1] * stock_data.shape[2])\n",
    "        all_predictions[date.year][stock_codes[stock]] = model.predict(stock_data, verbose = 0).tolist()\n",
    "        # save numpy array to disk\n",
    "        # np.save(f'predictions/{date.year}/{date.date().strftime(\"%Y%m%d\")}_{stock_codes[stock]}_predictions.npy', predictions)\n",
    "    \n",
    "    import pandas as pd\n",
    "    pd.DataFrame(all_predictions).to_csv(f'predictions/{date.date().strftime(\"%Y%m%d\")}_predictions.csv')\n",
    "    # X_test_array = X_test_array.reshape(X_test_array.shape[0] * X_test_array.shape[1], X_test_array.shape[2])\n",
    "    # y_test_array = y_test_array.reshape(y_test_array.shape[0] * y_test_array.shape[1], y_test_array.shape[2])\n",
    "    # # print(X_test_array.shape)\n",
    "    # test_loss = model.evaluate(X_test_array, y_test_array, batch_size=1)\n",
    "    # print(\"Test loss:\", test_loss)\n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame({\n",
    "#     \"2000\":{'a':[1,2,3],\n",
    "#     'b':[1,2,3]},\n",
    "#     \"2001\":{'a':[1,2,3],\n",
    "#     'b':[1,2,3]},\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = apply_lstm_model(final_4d_array, df_sub, stock_codes)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save keras model\n",
    "# model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_annually(df, start_date, end_date, window_size=2):\n",
    "    # models = []\n",
    "    # iterate between start_date and end_date with 1 year step size\n",
    "    while start_date < end_date:\n",
    "        next_year = start_date + relativedelta(years=1)\n",
    "        print(start_date, next_year)\n",
    "        if next_year > end_date:\n",
    "            next_year = end_date\n",
    "        final_4d_array, df_sub, stock_codes = get_pre_processed_data(df, start_date, next_year, window_size)\n",
    "        print(\"Got pre-processed data\")\n",
    "        model = apply_lstm_model(final_4d_array, df_sub, stock_codes, start_date)\n",
    "        model.save(f'models/lstm_model_{start_date.date().strftime(\"%Y%m%d\")}.keras')\n",
    "        start_date = next_year\n",
    "        # models.append(model)\n",
    "    # return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-31 00:00:00 2001-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 0.0976\n",
      "Epoch 2/2\n",
      "\u001b[1m760/760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - loss: 0.0058\n",
      "Train loss: 0.03603481873869896\n",
      "2001-01-31 00:00:00 2002-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - loss: 0.0052\n",
      "Epoch 2/2\n",
      "\u001b[1m709/709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 0.0034\n",
      "Train loss: 0.005277159623801708\n",
      "2002-01-31 00:00:00 2003-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - loss: 0.0120\n",
      "Epoch 2/2\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.0029\n",
      "Train loss: 0.003223957261070609\n",
      "2003-01-31 00:00:00 2004-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - loss: 0.0016\n",
      "Epoch 2/2\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - loss: 0.0016\n",
      "Train loss: 0.001627884921617806\n",
      "2004-01-31 00:00:00 2005-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - loss: 0.0177\n",
      "Epoch 2/2\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.0525\n",
      "Train loss: 0.13163642585277557\n",
      "2005-01-31 00:00:00 2006-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - loss: 0.1071\n",
      "Epoch 2/2\n",
      "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 0.1583\n",
      "Train loss: 0.070039764046669\n",
      "2006-01-31 00:00:00 2007-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - loss: 0.0175\n",
      "Epoch 2/2\n",
      "\u001b[1m576/576\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.0099\n",
      "Train loss: 0.01655074954032898\n",
      "2007-01-31 00:00:00 2008-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - loss: 3.5354\n",
      "Epoch 2/2\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 1.3327\n",
      "Train loss: 1.8628273010253906\n",
      "2008-01-31 00:00:00 2009-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632us/step - loss: 0.0300\n",
      "Epoch 2/2\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.0128\n",
      "Train loss: 0.013440659269690514\n",
      "2009-01-31 00:00:00 2010-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - loss: 0.0122\n",
      "Epoch 2/2\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - loss: 0.0145\n",
      "Train loss: 0.020044496282935143\n",
      "2010-01-31 00:00:00 2011-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - loss: 6.8647\n",
      "Epoch 2/2\n",
      "\u001b[1m366/366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 20.2942\n",
      "Train loss: 56.635643005371094\n",
      "2011-01-31 00:00:00 2012-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - loss: 0.0411\n",
      "Epoch 2/2\n",
      "\u001b[1m471/471\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.0226\n",
      "Train loss: 0.016173256561160088\n",
      "2012-01-31 00:00:00 2013-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - loss: 0.3072\n",
      "Epoch 2/2\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.2300\n",
      "Train loss: 0.6964656114578247\n",
      "2013-01-31 00:00:00 2014-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - loss: 0.0139\n",
      "Epoch 2/2\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.0065\n",
      "Train loss: 0.0036460987757891417\n",
      "2014-01-31 00:00:00 2015-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - loss: 0.0028\n",
      "Epoch 2/2\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - loss: 0.0010\n",
      "Train loss: 0.0009430606150999665\n",
      "2015-01-31 00:00:00 2016-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - loss: 0.0247\n",
      "Epoch 2/2\n",
      "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0020  \n",
      "Train loss: 0.006081108469516039\n",
      "2016-01-31 00:00:00 2017-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - loss: 0.0392\n",
      "Epoch 2/2\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0061\n",
      "Train loss: 0.020324591547250748\n",
      "2017-01-31 00:00:00 2018-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - loss: 0.0038\n",
      "Epoch 2/2\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - loss: 0.0044\n",
      "Train loss: 0.020541511476039886\n",
      "2018-01-31 00:00:00 2019-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - loss: 0.0124\n",
      "Epoch 2/2\n",
      "\u001b[1m428/428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.0179\n",
      "Train loss: 0.013303754851222038\n",
      "2019-01-31 00:00:00 2020-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - loss: 0.0881 \n",
      "Epoch 2/2\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.5350\n",
      "Train loss: 0.27423614263534546\n",
      "2020-01-31 00:00:00 2021-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - loss: 0.5050\n",
      "Epoch 2/2\n",
      "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 0.7240\n",
      "Train loss: 0.45346546173095703\n",
      "2021-01-31 00:00:00 2022-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - loss: 0.0057\n",
      "Epoch 2/2\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - loss: 0.0060\n",
      "Train loss: 0.005467918701469898\n",
      "2022-01-31 00:00:00 2023-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - loss: 0.0187\n",
      "Epoch 2/2\n",
      "\u001b[1m526/526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0210\n",
      "Train loss: 0.030349791049957275\n",
      "2023-01-31 00:00:00 2024-01-31 00:00:00\n",
      "Got pre-processed data\n",
      "Epoch 1/2\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - loss: 0.3211\n",
      "Epoch 2/2\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.2996\n",
      "Train loss: 0.24311377108097076\n"
     ]
    }
   ],
   "source": [
    "train_model_annually(df, start_date, end_date, window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
