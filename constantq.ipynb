{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Read the Feather file\n",
    "df = pd.read_feather('CRSP_daily_data_for_project(Technical_Analysis).feather')\n",
    "# df = df[(df['PERMNO']==10000) |( df['PERMNO']==10001)|(df['PERMNO']==10002)| (df['PERMNO']==93434)|(df['PERMNO']==93435)|(df['PERMNO']==93436)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.3750</td>\n",
       "      <td>2.56250</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.014954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2.3750</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>-0.020750</td>\n",
       "      <td>-0.005135</td>\n",
       "      <td>-0.027268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2.3750</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>-0.011315</td>\n",
       "      <td>-0.011659</td>\n",
       "      <td>-0.008944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.625</td>\n",
       "      <td>2.3750</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>-0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>2.62500</td>\n",
       "      <td>5450.0</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-06-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.011143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-06-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-06-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.004236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008518</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.009674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PERMNO        date  Open   High     Low    Close   Volume  SHROUT  \\\n",
       "1     10000  1986-01-07   NaN  2.750  2.3750  2.56250   1000.0  3680.0   \n",
       "2     10000  1986-01-08   NaN  2.625  2.3750  2.50000  12800.0  3680.0   \n",
       "3     10000  1986-01-09   NaN  2.625  2.3750  2.50000   1400.0  3680.0   \n",
       "4     10000  1986-01-10   NaN  2.625  2.3750  2.50000   8500.0  3680.0   \n",
       "5     10000  1986-01-13   NaN  2.750  2.5000  2.62500   5450.0  3680.0   \n",
       "..      ...         ...   ...    ...     ...      ...      ...     ...   \n",
       "359   10000  1987-06-08   NaN  0.250  0.1875  0.21875      0.0  3893.0   \n",
       "360   10000  1987-06-09   NaN  0.250  0.1875  0.21875      0.0  3893.0   \n",
       "361   10000  1987-06-10   NaN  0.250  0.1875  0.21875      0.0  3893.0   \n",
       "362   10000  1987-06-11   NaN  0.250  0.1875  0.21875    500.0  3893.0   \n",
       "363   10000  1987-06-12   NaN    NaN     NaN      NaN      NaN     NaN   \n",
       "\n",
       "       vwretx    ewretx    sprtrn  \n",
       "1    0.013800  0.011046  0.014954  \n",
       "2   -0.020750 -0.005135 -0.027268  \n",
       "3   -0.011315 -0.011659 -0.008944  \n",
       "4    0.000047  0.003632 -0.000728  \n",
       "5    0.002680  0.002369  0.003690  \n",
       "..        ...       ...       ...  \n",
       "359  0.008563  0.001508  0.011143  \n",
       "360  0.001918  0.002217  0.001887  \n",
       "361  0.001492  0.001049  0.000639  \n",
       "362  0.003427  0.002650  0.004236  \n",
       "363  0.008518  0.003921  0.009674  \n",
       "\n",
       "[363 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['PERMNO']==10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df['date']=df['date'].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-12-29 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Generate CQT data for each stock\n",
    "def create_cqt_df(stock_df, n_bins=20):\n",
    "    stock_returns = stock_df['vwretx'].values\n",
    "\n",
    "    # Data preprocessing: Ensure all values are finite\n",
    "    stock_returns = np.nan_to_num(stock_returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    sr = 1\n",
    "    fmin = 0.01  # Minimum frequency\n",
    "    hop_length = 1\n",
    "    cqt_result = librosa.cqt(stock_returns, n_bins=n_bins, sr=sr, hop_length=hop_length, fmin=fmin)\n",
    "    cqt_result_db = librosa.amplitude_to_db(np.abs(cqt_result), ref=np.mean)\n",
    "\n",
    "    cqt_df = pd.DataFrame(cqt_result_db.T, columns=[f'CQT_{i+1}' for i in range(cqt_result_db.shape[0])])\n",
    "    cqt_df = cqt_df.loc[:len(stock_df)-1, :]  # Ensure the length matches the original data\n",
    "    cqt = pd.concat([stock_df['date'], cqt_df], axis=1)\n",
    "    return cqt\n",
    "\n",
    "# Function: Create rolling windows and retain date indices\n",
    "def create_rolling_windows_with_dates(data, cqt_window_size, date_to_index):\n",
    "    windows = []\n",
    "    date_indices = []\n",
    "    for i in range(len(data) - cqt_window_size + 1):\n",
    "        window = data.iloc[i:i + cqt_window_size, 1:].values  # Exclude the date column, keep only CQT data\n",
    "        windows.append(window)\n",
    "        start_date = data.iloc[i]['date']\n",
    "        if start_date in date_to_index:\n",
    "            date_indices.append(date_to_index[start_date])\n",
    "    return np.array(windows), date_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pre_processed_data(df, start_date, end_date, window_size=30):\n",
    "    \n",
    "    df_sub = df[(df['date']>=start_date) & (df['date']<=end_date)]\n",
    "\n",
    "    # Get the list of all stock codes\n",
    "    stock_codes = set(df_sub['PERMNO'].unique())\n",
    "    # stock_codes = set()\n",
    "\n",
    "    cqt_window_size = window_size\n",
    "    n_bins = 20  # Number of CQT bins\n",
    "\n",
    "    # Get all unique dates\n",
    "    unique_dates = df_sub['date'].unique()\n",
    "\n",
    "    # drop the PERMNO for which data is not available on all unique_dates\n",
    "    for _,r in df_sub.groupby(['date']):\n",
    "        stock_codes.intersection_update(set(r['PERMNO'].to_list()))\n",
    "\n",
    "    stock_codes = list(stock_codes)\n",
    "    \n",
    "    df_sub = df_sub[df_sub['PERMNO'].isin(stock_codes)]\n",
    "    \n",
    "    # Create the 4D array, initialized with NaN\n",
    "    num_dates = len(unique_dates)\n",
    "    max_shape = (len(stock_codes), num_dates - cqt_window_size + 1, cqt_window_size, n_bins)\n",
    "    final_4d_array = np.full(max_shape, np.nan)\n",
    "\n",
    "    # Create the date-to-index mapping\n",
    "    date_to_index = {date: idx for idx, date in enumerate(unique_dates)}\n",
    "\n",
    "    # Create the stock code-to-index mapping\n",
    "    stock_code_to_index = {stock_code: idx for idx, stock_code in enumerate(stock_codes)}\n",
    "\n",
    "    # Iterate over each stock and fill the 4D array\n",
    "    for stock_code in stock_codes:\n",
    "        stock_idx = stock_code_to_index[stock_code]\n",
    "        stock_data = df_sub[df_sub['PERMNO'] == stock_code].reset_index(drop=True)\n",
    "        \n",
    "        # Generate CQT data\n",
    "        cqt_data = create_cqt_df(stock_data, n_bins)\n",
    "\n",
    "        # Create rolling windows and retain date indices\n",
    "        rolling_windows_3d, date_indices = create_rolling_windows_with_dates(cqt_data, cqt_window_size, date_to_index)\n",
    "        \n",
    "        # Fill the 4D array\n",
    "        for window_idx, (window_data, date_idx) in enumerate(zip(rolling_windows_3d, date_indices)):\n",
    "            if window_data.shape == (cqt_window_size, n_bins):\n",
    "                final_4d_array[stock_idx, date_idx, :, :] = window_data\n",
    "\n",
    "    df_sub = df_sub.sort_values(by=['PERMNO', 'date'])\n",
    "    df_sub['Ret'] = df_sub.groupby('PERMNO')['Close'].apply(lambda x: x.shift(-30).pct_change()).reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "    return final_4d_array, df_sub, stock_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1969-01-02 00:00:00')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df['date'].min()\n",
    "end_date = df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime.strptime(\"2000-01-01\", \"%Y-%m-%d\")\n",
    "# end_date = datetime.strptime(\"2001-01-01\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# final_4d_array, df_sub, stock_codes = get_pre_processed_data(df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock=0\n",
    "# stock_data = final_4d_array[stock]\n",
    "# ret = df_sub[df_sub.PERMNO == stock_codes[stock]]['Ret'].values[-stock_data.shape[0]:].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(final_4d_array.shape[1], 1)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# stock_data = scaler.fit_transform(stock_data.reshape(stock_data.shape[0], stock_data.shape[1] * stock_data.shape[2]))\n",
    "\n",
    "# # Split the data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(stock_data, ret, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub[df_sub['PERMNO']==32791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_4d_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LSTM model to the CQT data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lstm_model(final_4d_array, df_sub, stock_codes, date):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(final_4d_array.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    # make an array to store all X_test\n",
    "    X_test_array = None\n",
    "    y_test_array = None\n",
    "    X_train_array = None\n",
    "    y_train_array = None\n",
    "\n",
    "    for stock in range(final_4d_array.shape[0]):\n",
    "        stock_data = final_4d_array[stock]\n",
    "        ret = df_sub[df_sub.PERMNO == stock_codes[stock]]['Ret'].values[-stock_data.shape[0]:].reshape(-1, 1)\n",
    "        # Normalize the data\n",
    "        scaler = MinMaxScaler()\n",
    "        stock_data = scaler.fit_transform(stock_data.reshape(stock_data.shape[0], stock_data.shape[1] * stock_data.shape[2]))\n",
    "\n",
    "        # Split the data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(stock_data, ret, test_size=0.2, shuffle=False)\n",
    "\n",
    "        if X_test_array is None:\n",
    "            X_test_array = np.zeros((final_4d_array.shape[0], X_test.shape[0], X_test.shape[1]))\n",
    "        if X_train_array is None:\n",
    "            X_train_array = np.zeros((final_4d_array.shape[0], X_train.shape[0], X_train.shape[1]))\n",
    "        \n",
    "        if y_test_array is None:\n",
    "            y_test_array = np.zeros((final_4d_array.shape[0], y_test.shape[0], y_test.shape[1]))\n",
    "        if y_train_array is None:\n",
    "            y_train_array = np.zeros((final_4d_array.shape[0], y_train.shape[0], y_train.shape[1]))\n",
    "            \n",
    "        X_test_array[stock] = X_test\n",
    "        X_train_array[stock] = X_train\n",
    "        y_test_array[stock] = y_test\n",
    "        y_train_array[stock] = y_train\n",
    "\n",
    "    X_train_array = X_train_array.reshape(X_train_array.shape[0] * X_train_array.shape[1], X_train_array.shape[2])\n",
    "    y_train_array = y_train_array.reshape(y_train_array.shape[0] * y_train_array.shape[1], y_train_array.shape[2])\n",
    "    # Train the model\n",
    "    train_loss = model.fit(X_train_array, y_train_array, epochs=10, batch_size=32, verbose=0)\n",
    "    test_loss = model.evaluate(X_test_array, y_test_array, batch_size=32, verbose=0)\n",
    "    \n",
    "    print(\"Train loss:\", train_loss)\n",
    "    print(\"Test loss:\", test_loss)\n",
    "\n",
    "    for stock in range(final_4d_array.shape[0]):\n",
    "        predictions = model.predict(X_test_array[stock])\n",
    "        # save numpy array to disk\n",
    "        np.save(f'predictions/{date.date().strftime(\"%Y%m%d\")}_{stock_codes[stock]}_test_predictions.npy', predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = apply_lstm_model(final_4d_array, df_sub, stock_codes)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save keras model\n",
    "# model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_annually(df, start_date, end_date, window_size=30):\n",
    "    # models = []\n",
    "    # iterate between start_date and end_date with 1 year step size\n",
    "    while start_date < end_date:\n",
    "        next_year = start_date + relativedelta(years=1)\n",
    "        print(start_date, next_year)\n",
    "        if next_year > end_date:\n",
    "            next_year = end_date\n",
    "        final_4d_array, df_sub, stock_codes = get_pre_processed_data(df, start_date, next_year, window_size)\n",
    "        model = apply_lstm_model(final_4d_array, df_sub, stock_codes, start_date)\n",
    "        model.save(f'models/lstm_model_{start_date.date().strftime(\"%Y%m%d\")}.keras')\n",
    "        start_date = next_year\n",
    "        # models.append(model)\n",
    "    # return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969-01-02 00:00:00 1970-01-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_model_annually(df, start_date, end_date, window_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
