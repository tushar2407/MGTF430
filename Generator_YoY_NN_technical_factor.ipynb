{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# import os\n",
    "# # List files in your Google Drive\n",
    "# !ls /content/drive/MyDrive/UCSD_Courses/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path\n",
    "save_path = '/content/drive/MyDrive/UCSD_Courses/Behavior_Finance/Hedge_fund_project_predicted_value/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (2.3.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/tush/miniconda3/envs/finance/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.3.1-cp312-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "Successfully installed torch-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_feather(\"/content/drive/MyDrive/UCSD_Courses/Data/df_daily_technical_indicators.feather\")\n",
    "df = pd.read_feather(\"df_daily_technical_indicators.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deciles(inser):\n",
    "    outser = pd.qcut(inser, q=10, labels=range(10))\n",
    "    return outser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a label if stock return > median. label = 1; else label = 0\n",
    "# when calculating median, eliminate meanless data points from padding value\n",
    "# median_return = df[df['Future 30 days return'] != 0].groupby('date')['Future 30 days return'].median()\n",
    "# df['median_return'] = df.index.get_level_values('date').map(median_return)\n",
    "# df['label'] = (df['Future 30 days return'] > df['median_return']).astype(int)\n",
    "df['label'] = df.groupby('date')['Future 30 days return'].apply(deciles).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Bollinger Band Percent</th>\n",
       "      <th>rsi</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Future 30 days return</th>\n",
       "      <th>Size</th>\n",
       "      <th>lag vwretx</th>\n",
       "      <th>lag ewretx</th>\n",
       "      <th>lag sprtrn</th>\n",
       "      <th>median_return</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10001</th>\n",
       "      <th>1986-02-26</th>\n",
       "      <td>0.895285</td>\n",
       "      <td>69.377403</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>-0.017736</td>\n",
       "      <td>16.428309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.002452</td>\n",
       "      <td>0.042313</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-02-27</th>\n",
       "      <td>0.851887</td>\n",
       "      <td>69.377403</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>-0.025592</td>\n",
       "      <td>15.141755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-02-28</th>\n",
       "      <td>0.979186</td>\n",
       "      <td>73.918841</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.768732</td>\n",
       "      <td>25.018615</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-03</th>\n",
       "      <td>0.590435</td>\n",
       "      <td>56.023616</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-0.380366</td>\n",
       "      <td>-3.246377</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.005390</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-04</th>\n",
       "      <td>0.573235</td>\n",
       "      <td>56.023616</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003870</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>-0.006610</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">93436</th>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>0.492374</td>\n",
       "      <td>46.000779</td>\n",
       "      <td>-0.036636</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>-0.045460</td>\n",
       "      <td>0.047293</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.405085</td>\n",
       "      <td>0.145829</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10</th>\n",
       "      <td>0.346916</td>\n",
       "      <td>38.538966</td>\n",
       "      <td>-0.039103</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>-0.046290</td>\n",
       "      <td>-0.030205</td>\n",
       "      <td>-0.048671</td>\n",
       "      <td>-0.002893</td>\n",
       "      <td>0.202686</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.008586</td>\n",
       "      <td>-0.014880</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>0.158942</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13</th>\n",
       "      <td>0.438164</td>\n",
       "      <td>42.411998</td>\n",
       "      <td>-0.036350</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>-0.043496</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>-0.036597</td>\n",
       "      <td>0.195481</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.155249</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-14</th>\n",
       "      <td>0.631862</td>\n",
       "      <td>49.111857</td>\n",
       "      <td>-0.029819</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>-0.039351</td>\n",
       "      <td>0.087238</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.342494</td>\n",
       "      <td>0.168656</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>0.155214</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-15</th>\n",
       "      <td>0.998316</td>\n",
       "      <td>57.217313</td>\n",
       "      <td>-0.019441</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>-0.033553</td>\n",
       "      <td>0.145248</td>\n",
       "      <td>-0.014639</td>\n",
       "      <td>0.749947</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>10</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>0.019075</td>\n",
       "      <td>0.106725</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32477610 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Bollinger Band Percent        rsi  MACD_12_26_9  \\\n",
       "PERMNO date                                                          \n",
       "10001  1986-02-26                0.895285  69.377403      0.009111   \n",
       "       1986-02-27                0.851887  69.377403      0.009368   \n",
       "       1986-02-28                0.979186  73.918841      0.010152   \n",
       "       1986-03-03                0.590435  56.023616      0.009341   \n",
       "       1986-03-04                0.573235  56.023616      0.008440   \n",
       "...                                   ...        ...           ...   \n",
       "93436  2023-11-09                0.492374  46.000779     -0.036636   \n",
       "       2023-11-10                0.346916  38.538966     -0.039103   \n",
       "       2023-11-13                0.438164  42.411998     -0.036350   \n",
       "       2023-11-14                0.631862  49.111857     -0.029819   \n",
       "       2023-11-15                0.998316  57.217313     -0.019441   \n",
       "\n",
       "                   MACDh_12_26_9  MACDs_12_26_9  Momentum       OBV  \\\n",
       "PERMNO date                                                           \n",
       "10001  1986-02-26       0.000926       0.008185  0.030612 -0.017736   \n",
       "       1986-02-27       0.000946       0.008421  0.030612 -0.025592   \n",
       "       1986-02-28       0.001450       0.008701  0.030303  0.768732   \n",
       "       1986-03-03       0.000372       0.008968 -0.009901 -0.380366   \n",
       "       1986-03-04      -0.000423       0.008863  0.000000  0.016461   \n",
       "...                          ...            ...       ...       ...   \n",
       "93436  2023-11-09       0.008824      -0.045460  0.047293  0.002503   \n",
       "       2023-11-10       0.007186      -0.046290 -0.030205 -0.048671   \n",
       "       2023-11-13       0.007146      -0.043496  0.010498  0.014638   \n",
       "       2023-11-14       0.009532      -0.039351  0.087238  0.009032   \n",
       "       2023-11-15       0.014112      -0.033553  0.145248 -0.014639   \n",
       "\n",
       "                         ATR  Future 30 days return Size  lag vwretx  \\\n",
       "PERMNO date                                                            \n",
       "10001  1986-02-26  16.428309               0.000000    2   -0.001791   \n",
       "       1986-02-27  15.141755               0.000000    2    0.001307   \n",
       "       1986-02-28  25.018615              -0.009804    3    0.010952   \n",
       "       1986-03-03  -3.246377               0.010000    2    0.001845   \n",
       "       1986-03-04  -4.666667               0.010000    1   -0.003870   \n",
       "...                      ...                    ...  ...         ...   \n",
       "93436  2023-11-09   0.405085               0.145829   10   -0.000455   \n",
       "       2023-11-10  -0.002893               0.202686   10   -0.008586   \n",
       "       2023-11-13  -0.036597               0.195481   10    0.013823   \n",
       "       2023-11-14   0.342494               0.168656   10   -0.000386   \n",
       "       2023-11-15   0.749947               0.066425   10    0.022639   \n",
       "\n",
       "                   lag ewretx  lag sprtrn  median_return label  \n",
       "PERMNO date                                                     \n",
       "10001  1986-02-26    0.000788   -0.002452       0.042313     3  \n",
       "       1986-02-27    0.003222    0.001117       0.046225     3  \n",
       "       1986-02-28    0.007195    0.012185       0.035714     3  \n",
       "       1986-03-03    0.005390    0.000661       0.037037     4  \n",
       "       1986-03-04    0.000720   -0.006610       0.037736     4  \n",
       "...                       ...         ...            ...   ...  \n",
       "93436  2023-11-09   -0.006451    0.001005       0.139057     5  \n",
       "       2023-11-10   -0.014880   -0.008084       0.158942     6  \n",
       "       2023-11-13    0.004011    0.015616       0.155249     6  \n",
       "       2023-11-14    0.000257   -0.000836       0.155214     5  \n",
       "       2023-11-15    0.030881    0.019075       0.106725     3  \n",
       "\n",
       "[32477610 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to numeric, forcing non-numeric values to NaNs\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df = df.replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative data the stock data got!\n",
    "df['data_cumcount'] = df.groupby('PERMNO').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the look_back_period as the time series length the model trained on\n",
    "look_back_period = 100\n",
    "begin_date = '2015-01-01'\n",
    "end_date = '2016-12-31'\n",
    "train_test_split_date = '2016-01-01'\n",
    "date = df.index.get_level_values('date')\n",
    "df_temp = df[(date>begin_date)&(date<=end_date)].copy()\n",
    "del date\n",
    "# We only want data point with enough lag information\n",
    "df_temp = df_temp[df_temp['data_cumcount'] > look_back_period]\n",
    "# eliminate meanless data points from padding value\n",
    "df_temp = df_temp[df_temp['Future 30 days return'] != 0]\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "# Generate Pair_PERMNO_date for future indexing\n",
    "df_temp['Pair_PERMNO_date'] = list(zip(df_temp['PERMNO'], df_temp['date']))\n",
    "# take the last day in the month as sample\n",
    "df_temp['date'] = pd.to_datetime(df_temp['date']).dt.to_period('M').astype(str)\n",
    "df_temp = df_temp.groupby(['PERMNO','date']).tail(1)\n",
    "\n",
    "# reset index to make it more convenient for future use\n",
    "df_temp = df_temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>Bollinger Band Percent</th>\n",
       "      <th>rsi</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Future 30 days return</th>\n",
       "      <th>Size</th>\n",
       "      <th>lag vwretx</th>\n",
       "      <th>lag ewretx</th>\n",
       "      <th>lag sprtrn</th>\n",
       "      <th>median_return</th>\n",
       "      <th>label</th>\n",
       "      <th>data_cumcount</th>\n",
       "      <th>Pair_PERMNO_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>10001</td>\n",
       "      <td>2015-01</td>\n",
       "      <td>0.144353</td>\n",
       "      <td>29.700467</td>\n",
       "      <td>-0.023386</td>\n",
       "      <td>-0.002639</td>\n",
       "      <td>-0.020747</td>\n",
       "      <td>-0.071038</td>\n",
       "      <td>-0.414548</td>\n",
       "      <td>-11.875583</td>\n",
       "      <td>-0.034314</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.010010</td>\n",
       "      <td>-0.001501</td>\n",
       "      <td>-0.013388</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>2</td>\n",
       "      <td>5367</td>\n",
       "      <td>(10001, 2015-01-28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>10001</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>0.750474</td>\n",
       "      <td>50.379245</td>\n",
       "      <td>-0.005768</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>-0.013045</td>\n",
       "      <td>0.068783</td>\n",
       "      <td>0.036489</td>\n",
       "      <td>6.318367</td>\n",
       "      <td>-0.011881</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.001476</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>3</td>\n",
       "      <td>5377</td>\n",
       "      <td>(10001, 2015-02-27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>10001</td>\n",
       "      <td>2015-03</td>\n",
       "      <td>0.807974</td>\n",
       "      <td>55.237872</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.214805</td>\n",
       "      <td>11.005684</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011441</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>-0.010810</td>\n",
       "      <td>5</td>\n",
       "      <td>5396</td>\n",
       "      <td>(10001, 2015-03-31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>10001</td>\n",
       "      <td>2015-04</td>\n",
       "      <td>0.640162</td>\n",
       "      <td>51.876286</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>-0.084449</td>\n",
       "      <td>8.591645</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>-0.005035</td>\n",
       "      <td>-0.003740</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>3</td>\n",
       "      <td>5417</td>\n",
       "      <td>(10001, 2015-04-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>10001</td>\n",
       "      <td>2015-05</td>\n",
       "      <td>0.542303</td>\n",
       "      <td>52.150620</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>-0.671347</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>-0.007921</td>\n",
       "      <td>4</td>\n",
       "      <td>5437</td>\n",
       "      <td>(10001, 2015-05-29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52650</th>\n",
       "      <td>1050263</td>\n",
       "      <td>93436</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>-0.206755</td>\n",
       "      <td>31.984428</td>\n",
       "      <td>-0.009318</td>\n",
       "      <td>-0.007537</td>\n",
       "      <td>-0.001781</td>\n",
       "      <td>-0.063251</td>\n",
       "      <td>-0.053368</td>\n",
       "      <td>-1.166506</td>\n",
       "      <td>-0.046513</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.001643</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.001954</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>2</td>\n",
       "      <td>883</td>\n",
       "      <td>(93436, 2016-08-31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52651</th>\n",
       "      <td>1050284</td>\n",
       "      <td>93436</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>0.413642</td>\n",
       "      <td>39.700502</td>\n",
       "      <td>-0.012351</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>-0.017188</td>\n",
       "      <td>0.023718</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>-0.058491</td>\n",
       "      <td>-0.076482</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.009267</td>\n",
       "      <td>-0.008515</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>1</td>\n",
       "      <td>904</td>\n",
       "      <td>(93436, 2016-09-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52652</th>\n",
       "      <td>1050305</td>\n",
       "      <td>93436</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>0.397155</td>\n",
       "      <td>46.215030</td>\n",
       "      <td>-0.005828</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>-0.007642</td>\n",
       "      <td>-0.055305</td>\n",
       "      <td>0.163188</td>\n",
       "      <td>-0.037706</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>0.135324</td>\n",
       "      <td>1</td>\n",
       "      <td>925</td>\n",
       "      <td>(93436, 2016-10-31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52653</th>\n",
       "      <td>1050326</td>\n",
       "      <td>93436</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>0.525233</td>\n",
       "      <td>46.580455</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>-0.014758</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.361069</td>\n",
       "      <td>0.211109</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.001947</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.025851</td>\n",
       "      <td>9</td>\n",
       "      <td>946</td>\n",
       "      <td>(93436, 2016-11-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52654</th>\n",
       "      <td>1050347</td>\n",
       "      <td>93436</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>0.820008</td>\n",
       "      <td>66.451639</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.020366</td>\n",
       "      <td>0.115626</td>\n",
       "      <td>-0.052720</td>\n",
       "      <td>0.434376</td>\n",
       "      <td>0.307062</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>9</td>\n",
       "      <td>967</td>\n",
       "      <td>(93436, 2016-12-30)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52655 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  PERMNO     date  Bollinger Band Percent        rsi  \\\n",
       "0           17   10001  2015-01                0.144353  29.700467   \n",
       "1           27   10001  2015-02                0.750474  50.379245   \n",
       "2           46   10001  2015-03                0.807974  55.237872   \n",
       "3           67   10001  2015-04                0.640162  51.876286   \n",
       "4           87   10001  2015-05                0.542303  52.150620   \n",
       "...        ...     ...      ...                     ...        ...   \n",
       "52650  1050263   93436  2016-08               -0.206755  31.984428   \n",
       "52651  1050284   93436  2016-09                0.413642  39.700502   \n",
       "52652  1050305   93436  2016-10                0.397155  46.215030   \n",
       "52653  1050326   93436  2016-11                0.525233  46.580455   \n",
       "52654  1050347   93436  2016-12                0.820008  66.451639   \n",
       "\n",
       "       MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9  Momentum       OBV  \\\n",
       "0         -0.023386      -0.002639      -0.020747 -0.071038 -0.414548   \n",
       "1         -0.005768       0.007277      -0.013045  0.068783  0.036489   \n",
       "2         -0.001508       0.003042      -0.004550  0.015228  0.214805   \n",
       "3          0.002436       0.001217       0.001219  0.004016 -0.084449   \n",
       "4          0.002739      -0.000648       0.003387  0.001984  0.119506   \n",
       "...             ...            ...            ...       ...       ...   \n",
       "52650     -0.009318      -0.007537      -0.001781 -0.063251 -0.053368   \n",
       "52651     -0.012351       0.004837      -0.017188  0.023718  0.013172   \n",
       "52652     -0.005828       0.002717      -0.008545 -0.007642 -0.055305   \n",
       "52653     -0.008084       0.006674      -0.014758  0.022768  0.020850   \n",
       "52654      0.030616       0.010250       0.020366  0.115626 -0.052720   \n",
       "\n",
       "             ATR  Future 30 days return  Size  lag vwretx  lag ewretx  \\\n",
       "0     -11.875583              -0.034314     3   -0.010010   -0.001501   \n",
       "1       6.318367              -0.011881     2   -0.001683   -0.000319   \n",
       "2      11.005684               0.001000     2    0.011441    0.006734   \n",
       "3       8.591645              -0.011000     1   -0.004006   -0.005035   \n",
       "4      -0.671347              -0.009901     1   -0.001340   -0.001135   \n",
       "...          ...                    ...   ...         ...         ...   \n",
       "52650  -1.166506              -0.046513    10   -0.001643   -0.000446   \n",
       "52651  -0.058491              -0.076482    10   -0.009267   -0.008515   \n",
       "52652   0.163188              -0.037706    10   -0.002635   -0.003908   \n",
       "52653   0.361069               0.211109    10    0.000770   -0.001947   \n",
       "52654   0.434376               0.307062    10    0.000517    0.001316   \n",
       "\n",
       "       lag sprtrn  median_return  label  data_cumcount     Pair_PERMNO_date  \n",
       "0       -0.013388       0.017212      2           5367  (10001, 2015-01-28)  \n",
       "1       -0.001476       0.009928      3           5377  (10001, 2015-02-27)  \n",
       "2        0.012237      -0.010810      5           5396  (10001, 2015-03-31)  \n",
       "3       -0.003740       0.007519      3           5417  (10001, 2015-04-30)  \n",
       "4       -0.001267      -0.007921      4           5437  (10001, 2015-05-29)  \n",
       "...           ...            ...    ...            ...                  ...  \n",
       "52650   -0.001954      -0.011100      2            883  (93436, 2016-08-31)  \n",
       "52651   -0.009321       0.014236      1            904  (93436, 2016-09-30)  \n",
       "52652   -0.003108       0.135324      1            925  (93436, 2016-10-31)  \n",
       "52653    0.001335       0.025851      9            946  (93436, 2016-11-30)  \n",
       "52654   -0.000293       0.013873      9            967  (93436, 2016-12-30)  \n",
       "\n",
       "[52655 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_temp[df_temp['date']<train_test_split_date]\n",
    "df_test = df_temp[df_temp['date']>=train_test_split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'label'\n",
    "X_train = df_train.drop(label_name, axis=1)\n",
    "X_test = df_test.drop(label_name, axis=1)\n",
    "\n",
    "y_train = df_train[label_name]\n",
    "y_test = df_test[label_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# F.one_hot(torch.tensor(0), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5367"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.get_loc(df_temp['Pair_PERMNO_date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(df.iloc[5367]['label'].tolist(), dtype=torch.int64), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, whole_data, X, y=None, augment=True):\n",
    "        self.whole_data = whole_data\n",
    "        self.X = X #torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = y if y is not None else None #torch.tensor(y, dtype=torch.float32) if y is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "\n",
    "        if self.y is not None:\n",
    "          x = []\n",
    "          y = []\n",
    "\n",
    "          permo_date_locator = df.index.get_loc(df_temp['Pair_PERMNO_date'][idx])\n",
    "          #get x given index\n",
    "          x_temp  = df.iloc[permo_date_locator-look_back_period+1:permo_date_locator+1].drop(['Future 30 days return', 'label', 'data_cumcount'], axis = 1).to_numpy()\n",
    "          x.append(x_temp)\n",
    "          #get y given index\n",
    "          y_temp = F.one_hot(torch.tensor(df.iloc[permo_date_locator]['label'], dtype=torch.int64), num_classes=10)\n",
    "          y.append(y_temp)\n",
    "\n",
    "          x = torch.tensor(x_temp, dtype=torch.float32)\n",
    "          y = torch.tensor(y_temp, dtype=torch.float32)\n",
    "          return x, y\n",
    "\n",
    "        else:\n",
    "          x = []\n",
    "          i = idx\n",
    "          permo_date_locator = df.index.get_loc(df_temp['Pair_PERMNO_date'][idx])\n",
    "          #get x given index\n",
    "          x_temp  = df.iloc[permo_date_locator-look_back_period+1:permo_date_locator+1].drop(['Future 30 days return', 'label', 'data_cumcount'], axis = 1).to_numpy()\n",
    "          x.append(x_temp)\n",
    "\n",
    "          x = torch.tensor(x_temp, dtype=torch.float32)\n",
    "\n",
    "          return x\n",
    "\n",
    "        '''\n",
    "    def get_time_series_sample(self, x):\n",
    "        return x\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Bollinger Band Percent</th>\n",
       "      <th>rsi</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>OBV</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Future 30 days return</th>\n",
       "      <th>Size</th>\n",
       "      <th>lag vwretx</th>\n",
       "      <th>lag ewretx</th>\n",
       "      <th>lag sprtrn</th>\n",
       "      <th>median_return</th>\n",
       "      <th>label</th>\n",
       "      <th>data_cumcount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10001</th>\n",
       "      <th>1986-02-26</th>\n",
       "      <td>0.895285</td>\n",
       "      <td>69.377403</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>-0.017736</td>\n",
       "      <td>16.428309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.002452</td>\n",
       "      <td>0.042313</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-02-27</th>\n",
       "      <td>0.851887</td>\n",
       "      <td>69.377403</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>-0.025592</td>\n",
       "      <td>15.141755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-02-28</th>\n",
       "      <td>0.979186</td>\n",
       "      <td>73.918841</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.768732</td>\n",
       "      <td>25.018615</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-03</th>\n",
       "      <td>0.590435</td>\n",
       "      <td>56.023616</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>-0.009901</td>\n",
       "      <td>-0.380366</td>\n",
       "      <td>-3.246377</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.005390</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-04</th>\n",
       "      <td>0.573235</td>\n",
       "      <td>56.023616</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016461</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003870</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>-0.006610</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">93436</th>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>0.492374</td>\n",
       "      <td>46.000779</td>\n",
       "      <td>-0.036636</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>-0.045460</td>\n",
       "      <td>0.047293</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.405085</td>\n",
       "      <td>0.145829</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>-0.006451</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>5</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10</th>\n",
       "      <td>0.346916</td>\n",
       "      <td>38.538966</td>\n",
       "      <td>-0.039103</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>-0.046290</td>\n",
       "      <td>-0.030205</td>\n",
       "      <td>-0.048671</td>\n",
       "      <td>-0.002893</td>\n",
       "      <td>0.202686</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.008586</td>\n",
       "      <td>-0.014880</td>\n",
       "      <td>-0.008084</td>\n",
       "      <td>0.158942</td>\n",
       "      <td>6</td>\n",
       "      <td>2694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13</th>\n",
       "      <td>0.438164</td>\n",
       "      <td>42.411998</td>\n",
       "      <td>-0.036350</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>-0.043496</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>-0.036597</td>\n",
       "      <td>0.195481</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.155249</td>\n",
       "      <td>6</td>\n",
       "      <td>2695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-14</th>\n",
       "      <td>0.631862</td>\n",
       "      <td>49.111857</td>\n",
       "      <td>-0.029819</td>\n",
       "      <td>0.009532</td>\n",
       "      <td>-0.039351</td>\n",
       "      <td>0.087238</td>\n",
       "      <td>0.009032</td>\n",
       "      <td>0.342494</td>\n",
       "      <td>0.168656</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>0.155214</td>\n",
       "      <td>5</td>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-15</th>\n",
       "      <td>0.998316</td>\n",
       "      <td>57.217313</td>\n",
       "      <td>-0.019441</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>-0.033553</td>\n",
       "      <td>0.145248</td>\n",
       "      <td>-0.014639</td>\n",
       "      <td>0.749947</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>10</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.030881</td>\n",
       "      <td>0.019075</td>\n",
       "      <td>0.106725</td>\n",
       "      <td>3</td>\n",
       "      <td>2697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32477610 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Bollinger Band Percent        rsi  MACD_12_26_9  \\\n",
       "PERMNO date                                                          \n",
       "10001  1986-02-26                0.895285  69.377403      0.009111   \n",
       "       1986-02-27                0.851887  69.377403      0.009368   \n",
       "       1986-02-28                0.979186  73.918841      0.010152   \n",
       "       1986-03-03                0.590435  56.023616      0.009341   \n",
       "       1986-03-04                0.573235  56.023616      0.008440   \n",
       "...                                   ...        ...           ...   \n",
       "93436  2023-11-09                0.492374  46.000779     -0.036636   \n",
       "       2023-11-10                0.346916  38.538966     -0.039103   \n",
       "       2023-11-13                0.438164  42.411998     -0.036350   \n",
       "       2023-11-14                0.631862  49.111857     -0.029819   \n",
       "       2023-11-15                0.998316  57.217313     -0.019441   \n",
       "\n",
       "                   MACDh_12_26_9  MACDs_12_26_9  Momentum       OBV  \\\n",
       "PERMNO date                                                           \n",
       "10001  1986-02-26       0.000926       0.008185  0.030612 -0.017736   \n",
       "       1986-02-27       0.000946       0.008421  0.030612 -0.025592   \n",
       "       1986-02-28       0.001450       0.008701  0.030303  0.768732   \n",
       "       1986-03-03       0.000372       0.008968 -0.009901 -0.380366   \n",
       "       1986-03-04      -0.000423       0.008863  0.000000  0.016461   \n",
       "...                          ...            ...       ...       ...   \n",
       "93436  2023-11-09       0.008824      -0.045460  0.047293  0.002503   \n",
       "       2023-11-10       0.007186      -0.046290 -0.030205 -0.048671   \n",
       "       2023-11-13       0.007146      -0.043496  0.010498  0.014638   \n",
       "       2023-11-14       0.009532      -0.039351  0.087238  0.009032   \n",
       "       2023-11-15       0.014112      -0.033553  0.145248 -0.014639   \n",
       "\n",
       "                         ATR  Future 30 days return  Size  lag vwretx  \\\n",
       "PERMNO date                                                             \n",
       "10001  1986-02-26  16.428309               0.000000     2   -0.001791   \n",
       "       1986-02-27  15.141755               0.000000     2    0.001307   \n",
       "       1986-02-28  25.018615              -0.009804     3    0.010952   \n",
       "       1986-03-03  -3.246377               0.010000     2    0.001845   \n",
       "       1986-03-04  -4.666667               0.010000     1   -0.003870   \n",
       "...                      ...                    ...   ...         ...   \n",
       "93436  2023-11-09   0.405085               0.145829    10   -0.000455   \n",
       "       2023-11-10  -0.002893               0.202686    10   -0.008586   \n",
       "       2023-11-13  -0.036597               0.195481    10    0.013823   \n",
       "       2023-11-14   0.342494               0.168656    10   -0.000386   \n",
       "       2023-11-15   0.749947               0.066425    10    0.022639   \n",
       "\n",
       "                   lag ewretx  lag sprtrn  median_return  label  data_cumcount  \n",
       "PERMNO date                                                                     \n",
       "10001  1986-02-26    0.000788   -0.002452       0.042313      3              0  \n",
       "       1986-02-27    0.003222    0.001117       0.046225      3              1  \n",
       "       1986-02-28    0.007195    0.012185       0.035714      3              2  \n",
       "       1986-03-03    0.005390    0.000661       0.037037      4              3  \n",
       "       1986-03-04    0.000720   -0.006610       0.037736      4              4  \n",
       "...                       ...         ...            ...    ...            ...  \n",
       "93436  2023-11-09   -0.006451    0.001005       0.139057      5           2693  \n",
       "       2023-11-10   -0.014880   -0.008084       0.158942      6           2694  \n",
       "       2023-11-13    0.004011    0.015616       0.155249      6           2695  \n",
       "       2023-11-14    0.000257   -0.000836       0.155214      5           2696  \n",
       "       2023-11-15    0.030881    0.019075       0.106725      3           2697  \n",
       "\n",
       "[32477610 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = TimeSeriesDataset(df, X_train, y_train)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building my NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "seed = 42\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simpler Model\n",
    "class SimpleConvEncoder(nn.Module):\n",
    "    def __init__(self, T, C):\n",
    "        super(SimpleConvEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=C, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Change shape to [B, C, T]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        return x\n",
    "\n",
    "# Define a simple Classification Head\n",
    "class SimpleClassificationHead(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(SimpleClassificationHead, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 4)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 4, 10)  # Output 1 node for binary classification\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Combine Encoder and Classification Head into one model\n",
    "class SimpleTimeSeriesModel(nn.Module):\n",
    "    def __init__(self, T, C, hidden_dim):\n",
    "        super(SimpleTimeSeriesModel, self).__init__()\n",
    "        self.encoder = SimpleConvEncoder(T, C)\n",
    "        self.classification_head = SimpleClassificationHead(T * 256, hidden_dim)  # Update input dim based on the flattened size\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x, ybatch=None):\n",
    "        x = self.encoder(x)  # x shape will be [B, T * 256] after flattening\n",
    "        logits = self.classification_head(x).squeeze(-1)  # logits shape will be [B]\n",
    "        loss = None\n",
    "        if ybatch is not None:\n",
    "            loss = self.loss_fn(logits, ybatch.float())\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping mechanism\n",
    "class EarlyStopping_Train:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.train_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, train_loss, model):\n",
    "        score = -train_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(train_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'Training loss did not improve for {self.counter} epochs')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(train_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, train_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Training loss decreased ({self.train_loss_min:.6f} --> {train_loss:.6f}). Saving model...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "        self.train_loss_min = train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'label'\n",
    "X = df_train.drop(label_name, axis=1)\n",
    "X_test = df_test.drop(label_name, axis=1)\n",
    "\n",
    "y = df_train[label_name]\n",
    "y_test = df_test[label_name]\n",
    "\n",
    "\n",
    "# Parameters\n",
    "T = look_back_period\n",
    "C = df_temp.shape[1]-8\n",
    "n_embd = T*C\n",
    "max_seq_length = n_embd\n",
    "n_layer = 2 # 6\n",
    "n_head = 4 # 4\n",
    "n_hidden = 1000 # 1000\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "epochs = 2000#1000\n",
    "patience = 10\n",
    "seed = 42\n",
    "learning_rate = 0.001#\n",
    "clip_value = 5.0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "# Train the model on the entire training data\n",
    "train_dataset = TimeSeriesDataset(df, X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "model = SimpleTimeSeriesModel(T, C, n_hidden ).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 1000  # Change this value as needed\n",
    "early_stopping = EarlyStopping_Train(patience=patience, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7503, -2.0977, -2.5557,  ..., -2.1471, -2.1478, -2.6472],\n",
      "        [-2.4844, -2.3567, -2.2039,  ..., -1.7311, -2.0843, -1.9502],\n",
      "        [-1.8576, -2.2922, -2.1078,  ..., -2.1968, -1.8404, -1.9151],\n",
      "        ...,\n",
      "        [-2.7343, -2.6347, -2.6284,  ..., -2.7131, -2.2426, -2.6448],\n",
      "        [-1.6914, -2.4425, -2.3417,  ..., -2.1362, -3.0606, -2.4508],\n",
      "        [-1.8981, -2.6332, -2.6645,  ..., -2.6176, -2.7258, -2.5079]],\n",
      "       device='mps:0', grad_fn=<SqueezeBackward1>)\n",
      "Epoch [1/1000], Train Loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for batch_idx, (xbatch, ybatch) in enumerate(train_loader):\n",
    "        xbatch, ybatch = xbatch.to(device), ybatch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out, loss = model(xbatch, ybatch)\n",
    "        # print(out)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_value)\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "        # break\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "    # break\n",
    "    # Early stopping\n",
    "    early_stopping(avg_train_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Load the last checkpoint with the best model\n",
    "# model.load_state_dict(torch.load('checkpoint.pth'))\n",
    "# Predict on the test data\n",
    "test_dataset = TimeSeriesDataset(df, X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for xbatch, ybatch in test_loader:\n",
    "        xbatch, ybatch = xbatch.to(device), ybatch.to(device)\n",
    "        out, loss = model(xbatch, ybatch)\n",
    "        probs = torch.sigmoid(out).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_preds.extend(torch.max(out, 1)[1].cpu().numpy())\n",
    "        all_labels.extend(torch.max(ybatch, 1)[1].cpu().numpy())\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs = np.array(all_probs)\n",
    "all_preds = np.array(all_preds).astype(int)\n",
    "all_labels = np.array(all_labels).astype(int)\n",
    "# all_preds_binary = (all_preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_preds_binary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0 17  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0]]\n",
      "F1 Score: 0.0216\n",
      "Hit Rate (Recall): 0.1094\n",
      "Positive Predictive Value (Precision): 0.0120\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "hit_rate = recall_score(all_labels, all_preds, average='weighted')\n",
    "ppv = precision_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Hit Rate (Recall): {hit_rate:.4f}\")\n",
    "print(f\"Positive Predictive Value (Precision): {ppv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "#X_test['p(0)'] = all_probs[:, 0]\n",
    "X_test['p(1)'] = all_probs\n",
    "X_test.reset_index()[['PERMNO','date','label','p(1)']].to_feather(save_path+end_date+'.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
